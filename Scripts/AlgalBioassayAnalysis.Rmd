---
title: "LEC 143 Algal Bioassay Analysis"
author: "Dr. Marta Shocket"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: true
---
# Introduction

This document contains all the information that you need to be able to complete the statistical analysis and make the figures for the LEC 143 lab report. This workshop may seem daunting and you may not be able to absorb everything while we are going through it together during the session. If that is the case, it is not a problem, do not worry.

First, this document is designed to be a reference sheet that you can refer back to after the session.

Second, you are not expected to be able to write your own code from scratch after one workshop This document provides templates for all of the code that you need. You will be simply be following along, running the provided code, and making some minor modifications at the end.

The goals of this practical are:

1. Become familiar with basic concepts and processes used for coding statistical analyses in R.
2. Create the figure and perform the statistical tests for one lake.
3. Learn how to modify the provided code to apply it to the other three lakes.

## How to Code

Beginning coders are often under the impression that more advanced programmers have all of the commands they need memorized and write everything out perfectly the first time. In fact, nothing could be farther from the truth.

The two most important skills you need to be a successful coder are:

1. Looking things up as you code them (either online or in help files) 
2. Debugging your code when it doesn't work

These skills are key parts of the coding process, no matter how advanced you become. Embrace them.

## Introduction to R, RStudio, and R Markdown

**R** is a free, open-source programming language designed for statistical computing and graphics. It is the most commonly used tool for statistical analysis in ecology. 

**RStudio** is a free, open-source Integrated Development Environment (IDE) that makes coding in R much easier.

This practical is written as an **R Markdown** document, which uses the `.Rmd` file extension. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents.

The RStudio window is divided into four quadrants:

- *Top left*: Code files - where you can see and edit your saved code files (called "**scripts**"), including this R markdown document. Some types of data can also be viewed here.
- *Bottom left*: `Console` - where you can input commands and see code that has been run. This is also where text-based output gets printed if you are using a regular R script instead of an R markdown file.
- *Top right*: `Environment` - where you can see the saved data objects in your current R workspace.
- *Bottom right*: `Help` - where you can look up documentation about specific commands. There is also a `Plots` tab where  image-based output appears if you are using a regular R script instead of an R markdown file.

An R markdown document has alternating code "chunks" (in grey) and text (in white). To run the code within a chunk, hit the **green triangle** "play button" in the top right corner of the chunk. The output (both text-based and image-based) for a chunk will appear directly below it.

When you click the `Knit` button at the top of the script file, a document will be generated that includes the text content, code chunks, and any output generated from the code.

## Introduction to Coding in R

Four essential building blocks of any coding language are:

1. operators
2. variables
3. functions
4. arguments

**Operators** are typically 1 or 2 character commands that correspond to very simple, common tasks. For instance, all of the basic mathematical symbols are operators in most programming languages (e.g., `+` (addition), `-` (subtraction), `*` (multiplication), and `/` (division). You can use operators in R to calculate basic maths. For instance, the input `5*4*3*2*1` will give the output `120`.

Data and code output can be saved as named **variables**, which allows you to refer to and use them later. You can think of variables as analogous to nouns. In R, we use the arrow operator `<-` to save variables. For instance, we can save the output from our command above using the code: `five_factorial <- 5*4*3*2*1`.

Then, whenever we use the variable `five_factorial`, R will substitute the value `120`. 

**Functions** are the commands that tell the program to do something. You can think of them as the verbs of a programming language. Functions are always followed by a set of parentheses. For instance, the function `getwd()` will provide your current working directory (the default location where R will read and save files).

Most functions also take inputs called **arguments** that go inside the parentheses. Arguments are generally either:

1) Data to process
2) Settings that tell the function how to process the data

For instance, the function `sqrt(x)` takes one argument, `x`, and calculates its square root. So `sqrt(4)` will return the value `2`. 

Now let's get started with our analysis!

# Prepare the Data

Preparing the data for an analysis is an underrated step in science. It's very important and always takes longer than you think it will.

## Set-up

The chunk below is where we load the package that we need for our analysis.

A package is a set of functions that are not part of the basic R installation but can be added on later. Packages can be written by anybody and range from extremely large, complex, general packages maintained by dozens of contributors to very small packages written by one person for a specific purpose.

The package we're using is called `tidyverse`, which is actually a collection of many packages. You can load the specific packages individually, or all together with one command as the tidyverse.  Specifically, we will be using these two packages:

1. `dplyr` - a package for wrangling and manipulating data
2. `ggplot2` - a package for plotting figures

Within a code chunk, **comments** are used to explain what the code does, and are denoted with a hash sign (`#`). This way R knows not to run them as code. It's always a good idea to comment your code as you work, so that if you come back to the code later or share it with someone else, it's (hopefully) clear what you did and why. 

```{r setup, message=FALSE}

# This command tells R to print the code itself (not just the text and code ouput) when it knits the Rmd document
knitr::opts_chunk$set(echo = TRUE)

# The library() function loads packages
library(tidyverse)

```

## Load the data

Now we need to load the data from our algal bioassay experiment. The data are in a comma separated values (`.csv`) file. The code below reads the csv file and saves it as a data frame object called `AB_data.`

A **data frame** is a specific type of object in R that has observations (rows) of variables (columns). Each column has a name and the rows are numbered sequentially.

After you load the data, you should see it pop up in the `Environment` panel in the top right quadrant of your R Studio window. The panel will display the basic structure of the data object. In this case `AB_data` has 148 observations of 6 variables.

There are two different ways to examine the data from inside `Environment` panel:

1. Click on the blue circle with the white triangle by the name of the data frame (`AB_data`) to see a preview of all columns and the first few rows.
2. Click on the name of the data frame to open it up as a tab in the script files panel.

You can also view the first six rows of data using the `head()` function.


```{r loaddata}

# Read in the data
AB_data <- read.csv("../Data/AlgalBioassay_data_forR.csv")

# Display the first 6 rows
head(AB_data)

```

## Wrangle the data

The data are currently in **wide format**, where each experimental treatment (Control, +N, +P, +NP) is its own column. This means that there are multiple observations of Chlorophyll a fluorescence in each row.

In order to plot and analyze the data in R, we need to convert them to **long format**, where each observation is in it's own row, and there is one column denoting which treatment that observation belongs to.

The dplyr function that converts wide format to long format is `pivot_longer`. It takes the following three arguments:

- `col`: all the columns containing observations that want to combine into one new variable
- `names_to`: the name of the new variable that will contain the old column names as labels
- `values_to`: the name of the new variable that will contain all of the combined observations

Functions that take multiple arguments assign them to specific settings using the setting name and an equal sign: `function(setting1 = input1, setting2 = input2)`.

A few other notes for understanding the code below:

- Tidyverse code uses the "**pipe**" operator: `%>%`. This operator passes a data object to the next function in the code as the first argument. The shortcut to type it is `ctrl + shift + m`.
- To refer to multiple variables as a single unit, we need to create a vector grouping them together. In R, we create vectors with the small letter `c` followed by a set of parentheses, and each object inside separated by a comma: `c(x, y, z)`.
- For existing objects, we can simply use their name to refer to them. However, to create a new variable (or other character-based data), we must use quotation marks to indicate that it is a string of characters rather than a reference to an existing object.

```{r pivotlongdata}

# Transform the data from wide format into long format
	# The first line saves our output and passes our input data down to the next command
	# The second line transforms the input data based on the three additional arguments
AB_data_long <- AB_data %>% 
	pivot_longer(col = c(Control, N, P, NP), names_to = "Treatment", values_to = "Chla")

# Look at the new data frame and compare it to the old one
head(AB_data_long)

```

You may notice the output here looks different from the data frame in the previous chunk. Tidyverse functions automatically output in **tibbles**, a slightly upgraded (and fully compatible) version of a data frame.

When you print a tibble, you'll notice that it also displays the data type for each variable: *Lake* and *Treatment* are character string (`<chr>`), *Day* is integer (`<int>`), and *Chla* is double-precision floating point (`<dbl>`), one way of storing decimal numbers.

This output actually highlights a problem with two of our data types, which we'll change in the data transformation section.

## Transform the Data

In this section, you'll learn two different ways to transform data. There are often multiple ways to accomplish a given task when coding. This is particularly true in R, because there is usually a base R way and a tidyverse way.

We'll use both methods (base R and tidyverse) to:

1. change data types
2. create new variables from existing ones

In R, many operations and functions can be performed on objects with multiple kinds of data structures. For instance, `a <- 2*b` will work on any numerical variable `b`, regardless of what structure it is - `b` could be a single number, a vector of many numbers, or even a 2-dimensional data frame of numbers. The output (`a`) will simply be the same structure as the input (`b`).

This is extremely convenient for performing the same calculation on entire columns or matrices, and is one of the reasons why coding is more powerful than performing calculations by hand in a spreadsheet like Excel or Google Sheets.

### About Data types

All data have a **type** that defines that values it can take and the operations that can be performed on it. We noted above that *Lake* and *Treatment* are character strings (`<chr>`). However, they need to be factors for our statistical analysis to work properly later on. 

**Factors** are used for categorical data with a fixed set of acceptable values, called **levels**.

In R, there is a set of functions that change data types and all follow the same general format: `as.factor()`, `as.character()`, `as.integer()`, `as.double()`, etc.

### Change data type using the base R method

In base R, you refer to a specific column in a data frame using the `$` symbol. For instance, our fluorescence observations are now in the column `AB_data_long$Chla`.

You can transform a variable by using the assignment operator (`<-`) to overwrite the old version with the new version.

```{r lakeasfactor}

# Change Lake type from an string to a factor 
AB_data_long$Lake <- as.factor(AB_data_long$Lake)

```

### Change data type using the tidyverse method

In tidyverse R, you transform variables using the `mutate()` function and an equal sign.

```{r treatmentasfactor}

# Change Treatment type from an string to a factor 
AB_data_long <- AB_data_long %>% 
	mutate(Treatment = as.factor(Treatment))

```

### Convert units using the base R method

In base R, you can create a new column with the assignment operator ( `<-`) if you use a new name so you aren't overwriting an old one.

We'll use this method to convert our fluorescence data from $\mu g/mL$ to $\mu g/L$.

```{r chlaunitconversion}

# Use the base R method to create a new variable with units converted from ug/mL to ug/L
AB_data_long$ChlaL <- AB_data_long$Chla*1000

```

### Log-transform using the tidyverse method

Similarly, in tidyverse `mutate()` will create a new column if you give it a new name so it's not overwriting an old one.

We'll use this method to log-transform our fluorescence data, because algae are single celled organisms that grow exponentially. In biology, exponential data is often log-transformed so it will look like a line when plotted in linear space.

In R, the `log()` function uses base $e$ (the natural logarithm) as the default setting (which is what we want).

```{r chlalogtransform}

# Use the tidyverse method to log-transform the data
AB_data_long <- AB_data_long %>% 
	mutate(lnChlaL = log(ChlaL))

```

### Replace infinite values with zero

Now we have a new problem: log-transformation doesn't work for zero values. It gives the value negative infinity (`-Inf` in R), which will mess up our plotting later. So we'll need to replace those values (in all of our Day 0 observations) with zeros.

The code below shows how to replace infinite values with 0 using both base R and tidyverse methods. Both methods use the function `is.infinite()` to determine which rows have infinite values.

```{r replaceinfinitevalues}

# Use the base R method to replace -Inf values with 0
	# Square brackets allow you to refer to specific cells/rows/columns in general, and which() allows you to select only on those cells that match a certain criteria (in this case, contain infinite values)
AB_data_long$lnChlaL[which(is.infinite(AB_data_long$lnChlaL))] <- 0

# Use the tidyverse method to replace -Inf values with 0
AB_data_long <- AB_data_long %>% 
	mutate(lnChlaL = replace(lnChlaL, is.infinite(lnChlaL), 0))

```

## Summarise the Data

We'll want to make our graphs using summarised versions of our data (means and standard errors), not the individual observations. This task is most easily done using the tidyverse function `summarise()`. This function will perform any mathematical calculation over different groupings of your data. We'll want to group by `Lake`, `Treatment`, and `Day`, so we can get the mean and standard error for each combination of those three variables.

The formulate for standard error is is standard deviation (`sd()`) divided by the square root of the number of observations. We have 12 observations for each combination of lake, treatment, and day.

```{r summarisedata}

# Summarise the data
AB_data_summary <- AB_data_long %>% 
	group_by(Lake, Treatment, Day) %>% 
	summarise(lnChlaMean = mean(lnChlaL), lnChlaSE = sd(lnChlaL)/sqrt(12)) %>% 
	ungroup()

# Print the table of summarised data
AB_data_summary

```

# Plot the Data

The tidyverse function for basic plotting is called `ggplot2()`. It works by first creating a plotting "aesthetic" (`aes()`) that specifies which data frame and variables you are wishing to plot, then layering points, lines, labels, etc. on top of it. Each layer is separated by a `+` sign, and usually put on a new line to make it easier to read. 

We'll start with a very simple figure, and slowly build up complexity to get the figure that we want for the lab report. This will help you get familiar with the general coding syntax.

We'll use this process to make one finished plot for Windermere North. Then you can use that code as a template to create plots for the other three lakes. 

## Plot for Windermere North

Here's a very basic plot of all the summarised data points for all four lakes.

```{r plotbasic}

fig_basic <- ggplot(data = AB_data_summary, aes(x = Day, y = lnChlaMean)) + # Specify the data, create the ggplot aesthetic with Chlorophyll over time, and store as the variable "fig_basic"
	geom_point() # Add a layer with points
print(fig_basic) # Print the plot

```

However, for the figures for the lab report, we'll want to plot each lake separately.

This means we need to use the `filter()` function from dplyr to subset our data, and then feed that smaller data frame into ggplot using the pipe operator (`%>%`).

We'll also want to color code the points and lines by treatment, so we can tell them apart. ggplot will automatically make a legend showing which color belongs to which treatment.


```{r plotWindN1}

fig_WindN1 <- AB_data_summary %>% # Specify the data and plot variable name and pipe the data down
	filter(Lake == "Windermere_North") %>% # Filter the data for Windermere North only and pipe it down again
	ggplot(aes(x = Day, y = lnChlaMean, colour = Treatment)) + # Create the aesthetic with treatments plotted as colours
	geom_point()
print(fig_WindN1)

```

We want lines between our points, so we'll add another layer.

We'll also make a couple other changes to improve the way it looks:

- Add an argument to `geom_point()` to make the points bigger so they stand out more.
- Change the theme from the default one to `theme_minimal` to make the background white.
- Add better axis labels with units. The expression(paste()) functions will allow us to print the greek letter $\mu$.
- Add a title showing which lake the figure corresponds to.

```{r plotWindN2}

fig_WindN2 <- AB_data_summary %>%
	filter(Lake == "Windermere_North") %>%
	ggplot(aes(x = Day, y = lnChlaMean, colour = Treatment)) +
	geom_point(size = 3) + # Make the points bigger this time
	geom_line() + # Add a lines layer
	labs(y = expression(paste("ln Chlorophyll (", mu, "g/L)")), x = "Time (days)", title = "Windermere North") + # Change the axis labels and add a title
	theme_minimal() # Change the background colour via the theme
print(fig_WindN2)

```

The last important step is to add in error bars showing the standard error.

As this means plotting additional data (not just `lnChlaMean` and `Day`, well need to create a new aesthetic in the geomerrorbar() function.

This function has arguments for `ymax` and `ymin` to give the height of the error bars above and below the data points, and `width` to give the width of the error bars.

Now that we're finished, we'll also save the file in our Figures folder.

```{r plotWindN3}

fig_WindN3 <- AB_data_summary %>% 
	filter(Lake == "Windermere_North") %>%
	ggplot(aes(x = Day, y = lnChlaMean, colour = Treatment)) +
	geom_point(size = 3) +
	geom_line() +
	geom_errorbar(aes(ymin = lnChlaMean - lnChlaSE, ymax = lnChlaMean + lnChlaSE), width = 0.75) + # Add the error bars layer
	labs(y = expression(paste("ln Chlorophyll (", mu, "g/L)")), x = "Time (days)", title = "Windermere North") +
	theme_minimal()
print(fig_WindN3)

# Save the final version of the figure in the Figures folder
	# The width and height are given in inches
ggsave("../Figures/FigWindN.jpeg", width = 6, height = 4)

```

## Plots for other lakes

Now that we have a finished figure for Windermere North, you'll need make plots for the other three lakes (Windermere South, Esthwaite, and Elterwater).

There are some empty code chunks below for you to use.

Highlight the code from the previous chunk (`plotWindN3`), and then copy and paste it into each of the chunks below.

There are 4 things that you'll need to change in each chunk to adapt the code for the other lakes.

1. Change the argument for `filter()` that subsets the data.

On the 2nd line, where it says `filter(Lake == "Windermere_North")`, you need to change the character string that specifies the lake. Remember that it needs to match the data frame **exactly**. You can use the environment tab to check how each lake name is spelled and formatted, or type the command `levels(AB_data_long$Lake)` into the console. The `levels()` function tells you all the levels that exist for a factor in a data frame. 

2. Change the title of the plot

On the 7th line, where it says `labs( ... , title = "Windermere North")`, you need to change the character string for each lake. This time you want to format it so the text is nice to read.

3. Change the name of the plot.

On the 1st line, where it says `fig_WindN3 <- AB_data_summary %>%`, you need to change the name to something different. I would recommend using the suffixes `WindS`, `Esthw`, and `Elter`, which all have 5 letters like `WindN`. It's very helpful to be consistent with your naming conventions.

4. Change the final `print()` command to match the new plot names from #3.

Otherwise you'll just print the old plot for Windermere North 4 times in a row. 

```{r plotWindS}

```

```{r plotEsthwaite}

```

```{r plotElterwater}

```

## Optional customisations

If you don't like the default colours that ggplot uses, you can change them.

Go back to the code chunk for your final figure. Make a new line and add the command: `scale_colour_manual(values = c("#990000", "blue", "green", "purple")) +`. (I suggest between `labs()` and `theme_minimal()`.)

Then play around and substitute your colours of choice for the values that I included above.

R has a library of colours that be specified using text (e.g., "blue"). You can also specify any colour that you want using hexidecimal colour codes, a six digit number. You can google "R color chart" or "hexadecimal color code chart" to help you find the colours that you want.

Other easy customisations:

- Change the line width by adding `size = x` to the `geom_line()`, where x is a number
- Change the point symbol by added `shape = ` to `geom_point()`, where x is a number between 0 and 25. (Google "R point shapes" to find out what shape each number corresponds to.)
- Change the theme; some interesting ones to try are `theme_classic`, `theme_light`, `theme_dark`, and `theme_void`. 

# Statistical Analysis

## ANOVA test

We're going to perform a statistical test called an ANOVA, which stands for ANalysis Of VAriance. ANOVAs are used when you have a predictor variable that is categorical (in our case, which nutrient was added) and you have more than 2 categories (we have four: Control, N, P, and NP). An ANOVA test will tell you if there are significant differences in your response variable based on the predictor variable categories, but it won't tell you which specific categories are different from each other.

Some important notes how to run the ANOVA tests and which data to use:

- Like all statistical tests, ANOVA must be performed using the individual observations (not the summarized data that we used to make the graphs).
- Our question - which nutrient is limiting - is answered by comparing the treatments for a given lake, so we'll run a separate test for each lake.
- We're interested in comparing the overall amount of algal growth between the four treatments, so we'll only be using the data from final Day (21).

This means we'll need to make different copies of our data frame that only contain the specific subsets of the data that we need to run each test.

### Subset the data

We'll subset the data by telling R to which data to include and which to exclude based on the relevant criteria.

The code below is the base R method for the exact same thing that we did with filter() (the tidyverse method) when we were plotting above.

In most programming languages, one equal sign (`=`) is used to assign values (like we do with arguments in R) and two equal signs (`==`) are used to test if two things are equal. Try typing the following text into the console and see what happens:

- `2 == 2`
- `2 == 3`
- `2 = 3`

Additionally, most programming languages have "and" and "or" operators that allow you to combine tests. In R, the "and" operator is the `&` symbol.

```{r subsetdata}

# Save subsets of your data with observations from Day 21 for each lake
AB_data_Day21Elter <- subset(x = AB_data_long, Day == 21 & Lake == "Elterwater")
AB_data_Day21Esthw <- subset(x = AB_data_long, Day == 21 & Lake == "Esthwaite")
AB_data_Day21WindN <- subset(x = AB_data_long, Day == 21 & Lake == "Windermere_North")
AB_data_Day21WindS <- subset(x = AB_data_long, Day == 21 & Lake == "Windermere_South")

```

Examine the data frames by clicking on their names in the `Environment` tab to make sure that R subsetted the data correctly.

### Run the test

Now we're ready to actually perform the ANOVA test using the `aov()` function, **which takes two arguments.**

To run a statistical test in R, you need to specify the model formula using mathematical language. R follows the standard statistical notation and uses the `~` (tilde) sign to indicate "y is predicted by x" as `y ~ x`.

```{r ANOVAtest}

# Perform the ANOVA test and save the output for each lake
AB_ANOVA_Elter <- aov(formula = lnChlaL ~ Treatment, data = AB_data_Day21Elter)
AB_ANOVA_Esthw <- aov(formula = lnChlaL ~ Treatment, data = AB_data_Day21Esthw)
AB_ANOVA_WindN <- aov(formula = lnChlaL ~ Treatment, data = AB_data_Day21WindN)
AB_ANOVA_WindS <- aov(formula = lnChlaL ~ Treatment, data = AB_data_Day21WindS)

# Examine the output for each lake using the summary() function
summary(AB_ANOVA_Elter)
summary(AB_ANOVA_Esthw)
summary(AB_ANOVA_WindN)
summary(AB_ANOVA_WindS)

```

## Post-hoc Tukey tests

Now we need to perform Post-hoc Tukey tests to figure out which treatments were significantly different from each other.

**IMPORTANT** - We will only perform the Tukey post-hoc test for the lakes that had a significant result from the ANOVA test.

In R, the Tukey test is performed directly on the saved ANOVA results.

```{r TukeyHSD}

# Perform the Tukey Post Hoc test for the lakes with significant ANOVA results
AB_TPH_WindN <- TukeyHSD(AB_ANOVA_WindN)
AB_TPH_WindS <- TukeyHSD(AB_ANOVA_WindS)

# Examine the output for both lakes
AB_TPH_WindN
AB_TPH_WindS

```

